version: '3.9'

services:
  backend:
    build:
      context: .
      dockerfile: docker/production.Dockerfile
      target: backend
      args:
        NEXT_PUBLIC_API_URL: ${NEXT_PUBLIC_API_URL:-http://localhost:3030/api}
    env_file:
      - .env.production
    environment:
      DATABASE_URL: ${DATABASE_URL}
      SHADOW_DATABASE_URL: ${SHADOW_DATABASE_URL:-}
      MAPBOX_ACCESS_TOKEN: ${MAPBOX_ACCESS_TOKEN:-}
      ML_SERVICE_URL: ${ML_SERVICE_URL:-http://ml-api:8000}
      PORT: 3000
    depends_on:
      ml-api:
        condition: service_started
    ports:
      - "${BACKEND_PORT:-3030}:3000"
    healthcheck:
      test: ["CMD", "node", "-e", "require('http').get('http://localhost:3000/health', res => process.exit(res.statusCode === 200 ? 0 : 1)).on('error', () => process.exit(1))"]
      interval: 30s
      timeout: 5s
      retries: 5
    networks:
      - bhl-net

  frontend:
    build:
      context: .
      dockerfile: docker/production.Dockerfile
      target: frontend
      args:
        NEXT_PUBLIC_API_URL: ${NEXT_PUBLIC_API_URL:-http://localhost:3030/api}
    env_file:
      - .env.production
    environment:
      NEXT_PUBLIC_API_URL: ${NEXT_PUBLIC_API_URL:-http://localhost:3030/api}
      PORT: 3001
    depends_on:
      backend:
        condition: service_healthy
    ports:
      - "${FRONTEND_PORT:-3031}:3001"
    networks:
      - bhl-net

  ml-api:
    build:
      context: .
      dockerfile: docker/api.Dockerfile
    volumes:
      - ./artifacts:/app/artifacts:ro
    environment:
      PORT: 8000
    ports:
      - "${ML_API_PORT:-3032}:8000"
    networks:
      - bhl-net

networks:
  bhl-net:
    driver: bridge
